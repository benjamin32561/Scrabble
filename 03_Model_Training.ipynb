{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b39fffd",
   "metadata": {},
   "source": [
    "# Model Training Pipeline\n",
    "\n",
    "Training models using the engineered features from Sprint 2 (02_Feature_Engineering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b564cfc",
   "metadata": {},
   "source": [
    "## 1. Load Engineered Features\n",
    "\n",
    "Loading the features created in `02_Feature_Engineering.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022178b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.read_csv('output/train_features_engineered.csv')\n",
    "y_train_full = pd.read_csv('output/train_target.csv').squeeze()\n",
    "X_test = pd.read_csv('output/test_features_engineered.csv')\n",
    "\n",
    "print(f\"  Training features: {X_train_full.shape}\")\n",
    "print(f\"  Training target: {y_train_full.shape}\")\n",
    "print(f\"  Test features: {X_test.shape}\")\n",
    "print(f\"\\n  Features: {X_train_full.shape[1]}\")\n",
    "print(f\"  Training samples: {X_train_full.shape[0]:,}\")\n",
    "print(f\"  Test samples: {X_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de123a",
   "metadata": {},
   "source": [
    "## 2. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69436ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"  Training: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  Validation: {X_val.shape[0]:,} samples\")\n",
    "print(f\"  Test: {X_test.shape[0]:,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e757d2",
   "metadata": {},
   "source": [
    "## 3. Preprocess Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ec047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "if categorical_features:\n",
    "    print(f\"  Categorical: {categorical_features}\")\n",
    "\n",
    "# Create preprocessor\n",
    "transformers = []\n",
    "if numeric_features:\n",
    "    transformers.append(('scaler', StandardScaler(), numeric_features))\n",
    "if categorical_features:\n",
    "    transformers.append(('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), categorical_features))\n",
    "\n",
    "if transformers:\n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "    \n",
    "    # Fit and transform\n",
    "    X_train_proc = preprocessor.fit_transform(X_train)\n",
    "    X_val_proc = preprocessor.transform(X_val)\n",
    "    X_test_proc = preprocessor.transform(X_test)\n",
    "    \n",
    "    print(f\"\\n✓ Preprocessing complete\")\n",
    "    print(f\"  Final feature count: {X_train_proc.shape[1]}\")\n",
    "else:\n",
    "    X_train_proc = X_train.values\n",
    "    X_val_proc = X_val.values\n",
    "    X_test_proc = X_test.values\n",
    "    print(\"\\n✓ No preprocessing needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04edff7d",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943a1faf",
   "metadata": {},
   "source": [
    "### 4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "rf.fit(X_train_proc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = rf.predict(X_train_proc)\n",
    "y_pred_val = rf.predict(X_val_proc)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "train_mape = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "val_r2 = r2_score(y_val, y_pred_val)\n",
    "val_mape = np.mean(np.abs((y_val - y_pred_val) / y_val)) * 100\n",
    "\n",
    "print(f\"\\nTraining Metrics:\")\n",
    "print(f\"  RMSE: {train_rmse:.2f}\")\n",
    "print(f\"  MAE:  {train_mae:.2f}\")\n",
    "print(f\"  MAPE: {train_mape:.2f}%\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  RMSE: {val_rmse:.2f}\")\n",
    "print(f\"  MAE:  {val_mae:.2f}\")\n",
    "print(f\"  MAPE: {val_mape:.2f}%\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "rf_results = {'model': 'RandomForest', 'train_rmse': train_rmse, 'train_r2': train_r2,\n",
    "              'val_rmse': val_rmse, 'val_r2': val_r2, 'val_mape': val_mape}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57cd6d9",
   "metadata": {},
   "source": [
    "### 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_model.fit(X_train_proc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = xgb_model.predict(X_train_proc)\n",
    "y_pred_val = xgb_model.predict(X_val_proc)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "train_mape = np.mean(np.abs((y_train - y_pred_train) / y_train)) * 100\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "val_r2 = r2_score(y_val, y_pred_val)\n",
    "val_mape = np.mean(np.abs((y_val - y_pred_val) / y_val)) * 100\n",
    "\n",
    "print(f\"\\nTraining Metrics:\")\n",
    "print(f\"  RMSE: {train_rmse:.2f}\")\n",
    "print(f\"  MAE:  {train_mae:.2f}\")\n",
    "print(f\"  MAPE: {train_mape:.2f}%\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"  RMSE: {val_rmse:.2f}\")\n",
    "print(f\"  MAE:  {val_mae:.2f}\")\n",
    "print(f\"  MAPE: {val_mape:.2f}%\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "\n",
    "xgb_results = {'model': 'XGBoost', 'train_rmse': train_rmse, 'train_r2': train_r2,\n",
    "               'val_rmse': val_rmse, 'val_r2': val_r2, 'val_mape': val_mape}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8cb6d",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison_df = pd.DataFrame([rf_results, xgb_results])\n",
    "comparison_df = comparison_df.sort_values('val_rmse')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "comparison_df.to_csv('output/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Comparison saved to output/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12100383",
   "metadata": {},
   "source": [
    "## 6. Visualize Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aa0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# RMSE\n",
    "comparison_df.plot(x='model', y=['train_rmse', 'val_rmse'], kind='bar', ax=axes[0], alpha=0.8)\n",
    "axes[0].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].legend(['Training', 'Validation'])\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# R²\n",
    "comparison_df.plot(x='model', y=['train_r2', 'val_r2'], kind='bar', ax=axes[1], alpha=0.8, color=['coral', 'skyblue'])\n",
    "axes[1].set_title('R² Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('R² Score')\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].legend(['Training', 'Validation'])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# MAPE\n",
    "comparison_df.plot(x='model', y='val_mape', kind='bar', ax=axes[2], alpha=0.8, color='green', legend=False)\n",
    "axes[2].set_title('MAPE Comparison (Validation)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('MAPE (%)')\n",
    "axes[2].set_xlabel('Model')\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Plot saved to output/model_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d862df56",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0375ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importance\n",
    "if hasattr(rf, 'feature_importances_'):\n",
    "    try:\n",
    "        feature_names = []\n",
    "        if 'scaler' in preprocessor.named_transformers_:\n",
    "            feature_names.extend(numeric_features)\n",
    "        if 'encoder' in preprocessor.named_transformers_:\n",
    "            ohe = preprocessor.named_transformers_['encoder']\n",
    "            cat_names = ohe.get_feature_names_out(categorical_features).tolist()\n",
    "            feature_names.extend(cat_names)\n",
    "        \n",
    "        if len(feature_names) != len(rf.feature_importances_):\n",
    "            feature_names = [f'feature_{i}' for i in range(len(rf.feature_importances_))]\n",
    "    except:\n",
    "        feature_names = [f'feature_{i}' for i in range(len(rf.feature_importances_))]\n",
    "    \n",
    "    rf_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'rf_importance': rf.feature_importances_\n",
    "    })\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "if hasattr(xgb_model, 'feature_importances_'):\n",
    "    xgb_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'xgb_importance': xgb_model.feature_importances_\n",
    "    })\n",
    "\n",
    "# Merge and compare\n",
    "importance_df = rf_importance.merge(xgb_importance, on='feature')\n",
    "importance_df['avg_importance'] = (importance_df['rf_importance'] + importance_df['xgb_importance']) / 2\n",
    "importance_df = importance_df.sort_values('avg_importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Features (Average Importance):\")\n",
    "print(importance_df.head(20)[['feature', 'rf_importance', 'xgb_importance', 'avg_importance']].to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "top_20 = importance_df.head(20)\n",
    "axes[0].barh(top_20['feature'][::-1], top_20['rf_importance'][::-1], alpha=0.7, color='skyblue')\n",
    "axes[0].set_xlabel('Importance', fontsize=12)\n",
    "axes[0].set_title('Top 20 Features - Random Forest', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "axes[1].barh(top_20['feature'][::-1], top_20['xgb_importance'][::-1], alpha=0.7, color='coral')\n",
    "axes[1].set_xlabel('Importance', fontsize=12)\n",
    "axes[1].set_title('Top 20 Features - XGBoost', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Feature importance plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d011c8",
   "metadata": {},
   "source": [
    "## 8. Generate Predictions with Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290229f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "best_model_name = comparison_df.iloc[0]['model']\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Validation RMSE: {comparison_df.iloc[0]['val_rmse']:.2f}\")\n",
    "print(f\"Validation MAPE: {comparison_df.iloc[0]['val_mape']:.2f}%\")\n",
    "print(f\"Validation R²: {comparison_df.iloc[0]['val_r2']:.4f}\")\n",
    "\n",
    "# Get the best model\n",
    "if best_model_name == 'RandomForest':\n",
    "    best_model = rf\n",
    "else:\n",
    "    best_model = xgb_model\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "test_predictions = best_model.predict(X_test_proc)\n",
    "\n",
    "print(f\"\\n✓ Generated {len(test_predictions)} predictions\")\n",
    "print(f\"  Mean: {test_predictions.mean():.2f}\")\n",
    "print(f\"  Std: {test_predictions.std():.2f}\")\n",
    "print(f\"  Min: {test_predictions.min():.2f}\")\n",
    "print(f\"  Max: {test_predictions.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5128fa8e",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({'rating': test_predictions})\n",
    "predictions_df.to_csv('output/predictions.csv', index=False)\n",
    "print(\"✓ Predictions saved to output/predictions.csv\")\n",
    "\n",
    "# Save best model\n",
    "import joblib\n",
    "model_path = f'output/best_model_{best_model_name.lower()}.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"✓ Best model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43612d0d",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ccc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 Models Trained: 2\")\n",
    "print(f\"   • Random Forest\")\n",
    "print(f\"   • XGBoost\")\n",
    "\n",
    "print(f\"\\n🏆 Best Model: {best_model_name}\")\n",
    "print(f\"   • Validation RMSE: {comparison_df.iloc[0]['val_rmse']:.2f}\")\n",
    "print(f\"   • Validation MAPE: {comparison_df.iloc[0]['val_mape']:.2f}%\")\n",
    "print(f\"   • Validation R²: {comparison_df.iloc[0]['val_r2']:.4f}\")\n",
    "\n",
    "print(f\"\\n📁 Output Files:\")\n",
    "print(f\"   • output/model_comparison.csv\")\n",
    "print(f\"   • output/model_comparison.png\")\n",
    "print(f\"   • output/feature_importance.png\")\n",
    "print(f\"   • output/predictions.csv\")\n",
    "print(f\"   • output/best_model_{best_model_name.lower()}.pkl\")\n",
    "\n",
    "print(f\"\\n✅ Training complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
